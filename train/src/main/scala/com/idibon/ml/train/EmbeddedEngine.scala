package com.idibon.ml.train

import com.idibon.ml.alloy.{Codec,IntentAlloy}
import com.idibon.ml.feature.{DocumentExtractor, FeaturePipeline, FeaturePipelineBuilder}
import com.idibon.ml.feature.indexer.IndexTransformer
import com.idibon.ml.feature.tokenizer.TokenTransformer
import com.idibon.ml.predict.Engine

import java.io.{DataInputStream, DataOutputStream}
import org.apache.spark.mllib.regression.LabeledPoint
import org.json4s._
import org.json4s.JsonDSL._
import org.json4s.native.JsonMethods.{compact, parse, render}
import scala.collection.mutable.{HashMap, ListBuffer}
import scala.io.Source


class EmbeddedEngine extends Engine {

  def start() = {
    start("/tmp/idiml.txt")
  }

  def start(filename: String) = {
    val alloy = new IntentAlloy()

    val pipeline = (FeaturePipelineBuilder.named("IntentPipeline")
      += (FeaturePipelineBuilder.entry("convertToIndex", new IndexTransformer, "convertToTokens"))
      += (FeaturePipelineBuilder.entry("convertToTokens", new TokenTransformer, "contentExtractor"))
      += (FeaturePipelineBuilder.entry("contentExtractor", new DocumentExtractor, "$document"))
      := ("convertToIndex"))

    // Load the data generated by idibin/bin/open_source_integration/export_training_to_idiml.rb
    // Using a loop here because operations can't occur in parallel since the pipeline accumulates index values over time.
    // Prime the index
    for (line <- Source.fromFile(filename).getLines()) {
      val json = parse(line)
      pipeline(json.asInstanceOf[JObject])
    }

    // Iterate over the data one more time now that the index is complete. This ensures that every feature vector
    // will now be the same size
    val labels = HashMap[String, ListBuffer[LabeledPoint]]()
    for (line <- Source.fromFile(filename).getLines()) {
      // Extract the label name and its sign (positive or negative)
      val json = parse(line)
      val JString(label) = json \ "annotations" \ "label" \ "name"
      val JBool(isPositive) = json \ "annotations" \ "isPositive"

      // If we haven't seen this label before, instantiate a list
      if (!labels.contains(label)) {
        labels(label) = new ListBuffer[LabeledPoint]()
      }

      // Assign a number that MLlib understands
      val labelNumeric = isPositive match {
        case true => 1.0
        case false => 0.0
      }

      // Run the pipeline to generate the feature vector
      val featureVector = pipeline(json.asInstanceOf[JObject]).head

      // Create labeled points
      labels(label) += LabeledPoint(labelNumeric, featureVector)
    }

    println(s"labels: $labels")

    // Save the pipeline definition
    val test = pipeline.save(alloy.writer.within("IntentPipeline"))
    val alloyMetaJson: JObject = ("IntentPipeline" -> test)
    val writer = alloy.writer.within("IntentPipeline").resource("config.json")
    Codec.String.write(writer, compact(render(alloyMetaJson)))

    // Load the pipeline definition again
    val reader = alloy.reader.within("IntentPipeline").resource("config.json")
    val config = Codec.String.read(reader)
    val newPipelineConfig: JObject = (parse(config) \ "IntentPipeline").asInstanceOf[JObject]
    val newPipeline2 = (new FeaturePipeline).load(alloy.reader().within("IntentPipeline"), Some(newPipelineConfig))

  }
}

